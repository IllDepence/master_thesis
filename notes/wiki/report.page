# structure

**Answer:**

* Why is this work important (introduction)?
* How was it done (methods)?
* What were the results (results)?
* What do those results mean (discussion)?

### typical structure

IMRaD (Introduction, Methods, Results and Discussion)

* Introduction
    * Background/Context
    * Problem
    * Justification
    * Objectives & Hypotheses/Research Questions
    * Research Method
    * Structure of the Thesis
* Related Work
* (Background)
* Approach / Methods (Algorithms and Implementation) / Experiments + Evaluation
* Conclusion
* Future work

### planned structure

* Introduction
    * Background  
        this is citation recommendation and this is why it is relevant  
        it's different from paper recommendation in its intention (paprec→toread, citrec→tocite)  
        also there's different approaches to it (collab.fil. / input=paper / input=sentence / …)  
        ‌‌  
        furthermore, there's these efforts for introducing explicit semantic representations into the scholarly discourse (ScholOnto, Kitamoto's Digital Criticism Platform, ...)  
        wouldn't it be nice to combine the two
    * Problem setting  
        explicit semantic representations frequently seen in IR but no large body of work applying them for citation recommendation  
        therefore investigate how they can be applied to citation recommendation
    * Method  
        generate a data set fit for investigation of citation recommendation employing named entities and claims  
        devise citation recommendation approach
        implement and evaluate
    * Structure of the thesis
* Related work
    * `<insert paper.bib>` (state of the art citrec, use of explicit semantic representations in adjacent fields, ...)
* Background  
    fill as needed (citrec terminology, NEL/R, claim extraction)
* Data set
    * Existing data sets  
        and why a new one was necessary
    * Data set creation  
        `<insert BIR paper here>`
    * Data set evaluation  
        `<insert BIR paper here>`
* Semantic approaches to citation recommendation  
        types of citations (naming an entity, backing up a claim, etc.)  
        how citations are embedded in sentences (integral/non-integral)
    * Fields of Study as names entities  
        "fixed vocab" with hierarchy (考えてみればgoing up hierarchy is so not compatible with re-prediction eval)
    * Claims
        * Tools for extracting claims
        * A model of aboutness closely tied to claim structure  
            unfeasibility of use of PredPatt output as is  
            resulting compromise model
* Evaluation
    * Special considerations for citation recommendation  
        train/test splitting (per cited doc, temporal, ...), re-recommendation, number of contexts describing a recommendation item, ...
    * Offline evaluation  
        pre-filtering experiments (knn, lsi, lda, fos, ...)  
        different evaluation settings (all, CSonly, comparison to MAG, ...)
        `<insert many numbers here>`
    * Online evaluation  
        `<insert future results here>`
* Conclusion  
    'twas nice but now I'm exhausted
* Future work  
    more sophisticated (i.e. actual) modeling of claims  
    argumentative structure  
    mby classifier of citation type in front

# general notes

### "story" the report tells

b/c of [too much](https://arxiv.org/stats/monthly_submissions) new content to keep track of (in general and for researchers as well), citrec is an active area of research with variations XYZ (collab.fil. / input=paper / input=sentence / ...)

explicit semantic representations frequently seen in IR but yet to be thoroughly examined in the context of citrec; therefore add to the body of work in this area/direction

for this, generate a data set fit for investigation of citrec employing NEs and claims, devise citrec approach, implement and evaluate

---

in data set chapter: proper investigation requires data set to be large, clean (esp. citation marker) and w/ resolved reference items. non existent, therefore created.

in part about claim based approach: *direct* usage of identified claims with complete predicate arguments unfeasible, therefore model of *"cited doc aboutness"* closely tied to claim structure. 

### preference picks

* integral/non-integral citations
* dependency grammar vs phrase structure (/constituency) grammar → universal dependencies
* *similarity search for mathematical expressions using MathML* (Yokoi2009)

### semi preference picks
* [WikiCite](https://meta.wikimedia.org/wiki/WikiCite), [Wikidata](https://www.wikidata.org/wiki/Wikidata:Main_Pagehttps://www.wikidata.org/wiki/Wikidata:Main_Page) and the [Initiative for Open Citations](https://i4oc.org/)
* cold start problem: *"with every new publication, new citation links are added to older work. In studies depending solely on the citation network, cutting-edge work is marginalized as they do not have any citations yet; this is a kind of 'cold-start problem'"* (Sugiyama2013)
* old citations being old: *"references and citations in a paper are static and never change, ..."* (Sugiyama2013)
* *"cite rec by similar sentences: "exploits the implicit human relevance judgements found in existing scientific articles"* (Duma2014)
* several disciplines have traditions of citation analysis (White2004) (applied linguistics, history and sociology of science, information science)
* important work can be absorbed into the background knowledge of a subject and is then no longer referenced (e.g. Einstein 1905 for the Theory of Relativity) (Swales1986)
    * morphological and syntactic evolutions:
        * discoveries become 'named' (Lotka's Law, the Mossbauer Effect)
        * Proper Name adjectivization takes place (Widdowsonian dichotomies, a Sinclo-Coulthardian approach)
* sth like Habernal2017's *base applied NLP in argumentation mining on "substantial research in argumentation itself"* but for claims (esp. PredPatt approach)