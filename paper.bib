% Encoding: UTF-8

@InProceedings{Faerber2018,
  author    = {Michael F{\"{a}}rber and Alexander Thiemann and Adam Jatowt},
  title     = {{A High-Quality Gold Standard for Citation-based Tasks}},
  booktitle = {{Proceedings of the 11th International Conference on Language Resources and Evaluation}},
  year      = {2018},
  series    = {{{LREC} 2018}},
  note      = {r},
  review    = {- created new data set for cit.rec. based on arXiv
- only compsci papers
- other data sets (most commonly used one is CiteSeerX) have two main problems: (1) noisy citation context, (2) no/low quality links of citations to cited publications
- latex parser GrabCite (also parses other formats)
- 90k papers (for 62k DBLP link), 15M sentences, 2.5M citation markers

- parser: https://github.com/agrafix/grabcite
- DBLP serach thingy: https://github.com/agrafix/papergrep},
}

@InProceedings{Levy2014,
  author    = {Levy, Ran and Bilu, Yonatan and Hershcovich, Daniel and Aharoni, Ehud and Slonim, Noam},
  title     = {Context Dependent Claim Detection},
  booktitle = {Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers},
  year      = {2014},
  pages     = {1489--1500},
  address   = {Dublin, Ireland},
  month     = {August},
  publisher = {Dublin City University and Association for Computational Linguistics},
  note      = {r},
  review    = {- detect claims (relevant for a given topic(=statement open for discussion)) in free text
- claims may represent an opinion (i.e. can't be checked for truth/falsity)
- classifies/ranks in 3 stages (candidate sentences -> claim within sentence -> ranking)
- uses word net
- uses a lot of existing parsers, features, etc.},
  url       = {http://www.aclweb.org/anthology/C14-1141},
}

@Article{Hassan2015,
  author    = {Hassan, Naeemul and Adair, Bill and Hamilton, James and Li, Chengkai and Tremayne, Mark and Yang, Jun and Yu, Cong},
  title     = {The Quest to Automate Fact-Checking},
  year      = {2015},
  month     = {10},
  note      = {r},
  booktitle = {Proceedings of the 2015 Computation + Journalism Symposium},
  review    = {- argue for pursuing the goal of fully automated fact checking
- uses political discourse as goto example (politicians making claims, voters juding claims for their truth)
- developed own tool ClaimBuster
- supervised ML using SVM (also tested other methods, SVM performed best)
- manually created features
- used AlchemyAPI for sentiment analysis
- no stemming or stop word removal
- POS tags
- used random forest classifier},
}

@Article{BuckinghamShum2000,
  author   = {Buckingham Shum, Simon and Motta, Enrico and Domingue, John},
  title    = {ScholOnto: an ontology-based digital library server for research documents and discourse},
  journal  = {International Journal on Digital Libraries},
  year     = {2000},
  volume   = {3},
  number   = {3},
  pages    = {237--248},
  month    = {Oct},
  issn     = {1432-5012},
  note     = {r (ch 1-3)},
  abstract = {The internet is rapidly becoming the first place for researchers to publish documents, but at present they receive little support in searching, tracking, analysing or debating concepts in a literature from scholarly perspectives. This paper describes the design rationale and implementation of ScholOnto, an ontology-based digital library server to support scholarly interpretation and discourse. It enables researchers to describe and debate via a semantic network the contributions a document makes, and its relationship to the literature. The paper discusses the computational services that an ontology-based server supports, alternative user interfaces to support interaction with a large semantic network, usability issues associated with knowledge formalisation, new work practices that could emerge, and related work.},
  day      = {01},
  doi      = {10.1007/s007990000034},
  review   = {- proposal to (manually) add semantic annotation to scientific texts (to enable network of contestable claims)
- introduce annotation scheme for above
- "discourse-oriented ontology"
- 90s style interface implementation},
  url      = {https://doi.org/10.1007/s007990000034},
}

@InProceedings{Goudas2014,
  author    = {Goudas, Theodosis and Louizos, Christos and Petasis, Georgios and Karkaletsis, Vangelis},
  title     = {Argument Extraction from News, Blogs, and Social Media},
  booktitle = {Artificial Intelligence: Methods and Applications},
  year      = {2014},
  editor    = {Likas, Aristidis and Blekas, Konstantinos and Kalles, Dimitris},
  pages     = {287--299},
  address   = {Cham},
  publisher = {Springer International Publishing},
  note      = {r},
  abstract  = {Argument extraction is the task of identifying arguments, along with their components in text. Arguments can be usually decomposed into a claim and one or more premises justifying it. Among the novel aspects of this work is the thematic domain itself which relates to Social Media, in contrast to traditional research in the area, which concentrates mainly on law documents and scientific publications. The huge increase of social media communities, along with their user tendency to debate, makes the identification of arguments in these texts a necessity. Argument extraction from Social Media is more challenging because texts may not always contain arguments, as is the case of legal documents or scientific publications usually studied. In addition, being less formal in nature, texts in Social Media may not even have proper syntax or spelling. This paper presents a two-step approach for argument extraction from social media texts. During the first step, the proposed approach tries to classify the sentences into ``sentences that contain arguments'' and ``sentences that don't contain arguments''. In the second step, it tries to identify the exact fragments that contain the premises from the sentences that contain arguments, by utilizing conditional random fields. The results exceed significantly the base line approach, and according to literature, are quite promising.},
  isbn      = {978-3-319-07064-3},
  review    = {- argument extraction from social media text
- corpus of 204 documents from social media in greek
- two step process: candidate sentences -> identify segments that contain premises
- mby usable citations for CRFs, logistic regeression, random forest, SMVs and naive bayes
- for first step logistic regressen worked best

- (!!!) names "number of named entities" as one feature of state of the art approaches to classify sentences into non-/argumentative (!!!)

- "popular search engines such as Bing" lol
- uses apparently long dead NLP platform Ellogon
- "CRFs are a structure prediction algorithm"},
}

@InProceedings{Mishra2016,
  author    = {Mishra, Arunav and Berberich, Klaus},
  title     = {Leveraging Semantic Annotations to Link Wikipedia and News Archives},
  booktitle = {Advances in Information Retrieval},
  year      = {2016},
  editor    = {Ferro, Nicola and Crestani, Fabio and Moens, Marie-Francine and Mothe, Josiane and Silvestri, Fabrizio and Di Nunzio, Giorgio Maria and Hauff, Claudia and Silvello, Gianmaria},
  pages     = {30--42},
  address   = {Cham},
  publisher = {Springer International Publishing},
  note      = {r (ch 1-3)},
  abstract  = {The incomprehensible amount of information available online has made it difficult to retrospect on past events. We propose a novel linking problem to connect excerpts from Wikipedia summarizing events to online news articles elaborating on them. To address this linking problem, we cast it into an information retrieval task by treating a given excerpt as a user query with the goal to retrieve a ranked list of relevant news articles. We find that Wikipedia excerpts often come with additional semantics, in their textual descriptions, representing the time, geolocations, and named entities involved in the event. Our retrieval model leverages text and semantic annotations as different dimensions of an event by estimating independent query models to rank documents. In our experiments on two datasets, we compare methods that consider different combinations of dimensions and find that the approach that leverages all dimensions suits our problem best.},
  isbn      = {978-3-319-30671-1},
  review    = {- for a small part of a wikipedia entry describing a historical event, find news articles (ranked list) describing the event in detail
- useses text, time, geolocations, names entities
- linking method unclear},
}

@Masterthesis{Paszcza2016,
  author = {Paszcza, Bartosz},
  title  = {Comparison of Microsoft Academic Graph with other scholarly citation databases},
  month  = {11},
  year   = {2016},
  note   = {r (ch 1,""3"")},
  pages  = {69},
  review = {- analysis of the MAG
-> relating its scope, openness, completeness of information and interoperability to WoS, Scopus, GS (three other scholarly citation datasets )
- written by a non(/not so much) tech person?},
}

@Article{Herrmannova2016,
  author    = {Drahomira Herrmannova and Petr Knoth},
  title     = {An Analysis of the Microsoft Academic Graph},
  journal   = {D-Lib Magazine},
  year      = {2016},
  volume    = {22},
  number    = {9/10},
  note      = {r},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/journals/dlib/HerrmannovaK16a},
  doi       = {10.1045/september2016-herrmannova},
  review    = {- analysis of MAG and comparison to other data sets

- MAG is over many disciplines (not just CS, of which it contains ~17 million papers)
- MAG is automatically assembled -> before using it for a task, the MAG should be checked for noise and bias (what this paper does)
- MAG is largest publicly available dataset of open citation data
- only 30 out of 127 million papers in MAG have citation data
- year of publication field is populated for all papers in MAG
- MAG contains 35 million DOIs
- field of study info in MAG is hierarchical (4 levels of granularity)

- look on citation network from several perspectives
- 80 million disconnected nodes (i.e. papers w/o citations (being cited) and references (citing))
- differences concerning journals' and universities' citation counts compared to other citation ranking sources (but no way to dig deeper since latter are non transparent)},
  timestamp = {Sun, 28 May 2017 13:24:39 +0200},
  url       = {https://doi.org/10.1045/september2016-herrmannova},
}

@Article{Hug2017,
  author   = {Hug, Sven E. and Ochsner, Michael and Br{\"a}ndle, Martin P.},
  title    = {Citation analysis with microsoft academic},
  journal  = {Scientometrics},
  year     = {2017},
  volume   = {111},
  number   = {1},
  pages    = {371--378},
  month    = {Apr},
  issn     = {1588-2861},
  note     = {r},
  abstract = {We explore if and how Microsoft Academic (MA) could be used for bibliometric analyses. First, we examine the Academic Knowledge API (AK API), an interface to access MA data, and compare it to Google Scholar (GS). Second, we perform a comparative citation analysis of researchers by normalizing data from MA and Scopus. We find that MA offers structured and rich metadata, which facilitates data retrieval, handling and processing. In addition, the AK API allows retrieving frequency distributions of citations. We consider these features to be a major advantage of MA over GS. However, we identify four main limitations regarding the available metadata. First, MA does not provide the document type of a publication. Second, the ``fields of study'' are dynamic, too specific and field hierarchies are incoherent. Third, some publications are assigned to incorrect years. Fourth, the metadata of some publications did not include all authors. Nevertheless, we show that an average-based indicator (i.e. the journal normalized citation score; JNCS) as well as a distribution-based indicator (i.e. percentile rank classes; PR classes) can be calculated with relative ease using MA. Hence, normalization of citation counts is feasible with MA. The citation analyses in MA and Scopus yield uniform results. The JNCS and the PR classes are similar in both databases, and, as a consequence, the evaluation of the researchers' publication impact is congruent in MA and Scopus. Given the fast development in the last year, we postulate that MA has the potential to be used for full-fledged bibliometric analyses.},
  day      = {01},
  doi      = {10.1007/s11192-017-2247-8},
  review   = {- 3 ways to access the MA(G)
-> a Academic Knowledge API (which allows retrieval of frequency distributions of citations): https://www.microsoft.com/cognitive-services/en-us/academic-knowledge-api
-> MA search engine: https://academic.microsoft.com
-> snapshot downloads: https://academicgraph.blob.core.windows.net/graph/index.html
- MA(G) does not provide document type of a publication (-> makes it difficult to distinguish between citable and not citable documents)
- MAG has more structured and richer metadata than Google Scholar
- MAG seems to miss authors (for one particular researcher, they're not listed as author in 64% of their publications)

- check feasability of performing a comparative citation analysis between researchers (here 3) using AK API},
  url      = {https://doi.org/10.1007/s11192-017-2247-8},
}

@InProceedings{Sinha2015,
  author    = {Sinha, Arnab and Shen, Zhihong and Song, Yang and Ma, Hao and Eide, Darrin and Hsu, Bo-June (Paul) and Wang, Kuansan},
  title     = {An Overview of Microsoft Academic Service (MAS) and Applications},
  booktitle = {Proceedings of the 24th International Conference on World Wide Web},
  year      = {2015},
  series    = {WWW '15 Companion},
  pages     = {243--246},
  address   = {New York, NY, USA},
  publisher = {ACM},
  note      = {r},
  acmid     = {2742839},
  doi       = {10.1145/2740908.2742839},
  isbn      = {978-1-4503-3473-0},
  keywords  = {academic search, entity conflation, recommender systems},
  location  = {Florence, Italy},
  numpages  = {4},
  review    = {- official citation in case of using MAG (see: https://microsoftdocs.github.io/microsoft-academic/microsoft-academic-graph/reference/data-schema.html)
- description of how MAG was created
-> heterogeneous entity graph containing entities of type: field of study, author, institution, paper, venue (i.e. journal/conference), event (specific conference instance)
- description of 2 applications
-> semantic search (e.g. "papers citing <author> before <year> about <field-of-study> appearing in <journal>")
-> recommendation (e.g. "given a field of study, find out the most prominent authors, the most influential papers, ...")},
  url       = {http://doi.acm.org/10.1145/2740908.2742839},
}

@Book{Besnard2008,
  title     = {Elements of Argumentation},
  publisher = {The MIT Press},
  year      = {2008},
  author    = {Besnard, Philippe and Hunter, Anthony},
  isbn      = {0262026430, 9780262026437},
}

@Unpublished{Faerber,
  author = {Michael F{\"{a}}rber and Adam Jatowt},
  title  = {{Citation Recommendation for Scientific Publications}},
  review = {-  (!!!) argument for semantic approach (!!!)
    "One can envision that, in the mid-term, citation recommendation approaches can better capture the semantics of the citation context, with the result that actual fact-based citation recommendation becomes reality."
    (chapter 6 POTENTIAL FUTURE WORK)},
}

@Article{Tbahriti2006,
  author   = {Imad Tbahriti and Christine Chichester and Frédérique Lisacek and Patrick Ruch},
  title    = {Using argumentation to retrieve articles with similar citations: An inquiry into improving related articles search in the MEDLINE digital library},
  journal  = {International Journal of Medical Informatics},
  year     = {2006},
  volume   = {75},
  number   = {6},
  pages    = {488 - 495},
  issn     = {1386-5056},
  doi      = {https://doi.org/10.1016/j.ijmedinf.2005.06.007},
  keywords = {Argumentation, MEDLINE, Citation, Information storage and retrieval, Related article search},
  review   = {- find documents with similar citations
- classify abstract sentences into purpose, methods, results, conclusion
- "system could also be used as a platform to aid authors by means of automatic assembly or refinement of their bibliographies through the suggestion of citations coming from documents containing similar arguments"},
  url      = {http://www.sciencedirect.com/science/article/pii/S1386505605000894},
}

@Article{Duma2016,
  author  = {Daniel Duma and Ewan Klein and Maria Liakata and James Ravenscroft and Amanda Clare},
  title   = {Rhetorical Classification of Anchor Text for Citation Recommendation},
  journal = {D-Lib Magazine},
  year    = {2016},
  volume  = {22},
}

@InProceedings{Liakata2010,
  author    = {Maria Liakata and Simone Teufel and Advaith Siddharthan and Colin R. Batchelor},
  title     = {Corpora for the Conceptualisation and Zoning of Scientific Papers},
  booktitle = {LREC},
  year      = {2010},
  note      = {READ!},
  review    = {- "a citation to a paper is accompanied by text that often summarizes a key point in the cited paper, or its contribution to the field. It has been found experimentally that there is useful information in these ILCs that is not found in the cited paper itself [17]"
- "We only consider resolvable citations, that is, citations to references that point to a paper that is in our collection, which means we have access to its metadata and full machine-readable contents"},
}

@InProceedings{Kobayashi2018,
  author    = {Kobayashi, Yuta and Shimbo, Masashi and Matsumoto, Yuji},
  title     = {Citation Recommendation Using Distributed Representation of Discourse Facets in Scientific Articles},
  booktitle = {Proceedings of the 18th ACM/IEEE on Joint Conference on Digital Libraries},
  year      = {2018},
  series    = {JCDL '18},
  pages     = {243--251},
  address   = {New York, NY, USA},
  publisher = {ACM},
  note      = {r (ch 1-2)},
  acmid     = {3197059},
  doi       = {10.1145/3197026.3197059},
  isbn      = {978-1-4503-5178-2},
  keywords  = {co-citation analysis, discourse facet, natural language processing, representation learning, scientific article},
  location  = {Fort Worth, Texas, USA},
  numpages  = {9},
  review    = {- only recommend "co-citations": given context *AND ONE CITATION*, recommend more appropriate citations
- "the Citation Function Corpus [33]"},
  url       = {http://doi.acm.org/10.1145/3197026.3197059},
}

@InProceedings{Sugiyama2013,
  author    = {Sugiyama, Kazunari and Kan, Min-Yen},
  title     = {Exploiting Potential Citation Papers in Scholarly Paper Recommendation},
  booktitle = {Proceedings of the 13th ACM/IEEE-CS Joint Conference on Digital Libraries},
  year      = {2013},
  series    = {JCDL '13},
  pages     = {153--162},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2467701},
  doi       = {10.1145/2467696.2467701},
  isbn      = {978-1-4503-2077-1},
  keywords  = {citation analysis, collaborative filtering, digital library, information retrieval, recommendation},
  location  = {Indianapolis, Indiana, USA},
  numpages  = {10},
  review    = {- cold start problem: "with every new publication, new citation links are added to older work. In studies depending solely on the citation network, cutting- edge work is marginalized as they do not have any citations yet; this is a kind of 'cold-start problem'"
- old citations being old: "references and citations in a paper are static and never change, newer relevant papers to older ones have the 'responsibility' of creating a citation link between them"
-> introduce artificial links into citation network},
  url       = {http://doi.acm.org/10.1145/2467696.2467701},
}

@InProceedings{Livne2014,
  author    = {Livne, Avishay and Gokuladas, Vivek and Teevan, Jaime and Dumais, Susan T. and Adar, Eytan},
  title     = {CiteSight: Supporting Contextual Citation Recommendation Using Differential Search},
  booktitle = {Proceedings of the 37th International ACM SIGIR Conference on Research \&\#38; Development in Information Retrieval},
  year      = {2014},
  series    = {SIGIR '14},
  pages     = {807--816},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2609585},
  doi       = {10.1145/2600428.2609585},
  isbn      = {978-1-4503-2257-7},
  keywords  = {citation recommendation, differential search., personalization},
  location  = {Gold Coast, Queensland, Australia},
  numpages  = {10},
  review    = {- use MA(G)
- "citations are power law distributed" (long tail) (w/ citation)
    -> use "citation coupling" to enrich the citation graph},
  url       = {http://doi.acm.org/10.1145/2600428.2609585},
}

@Article{HERNANDEZ-ALVAREZ2016,
  author    = {HERNÁNDEZ-ALVAREZ, MYRIAM and GOMEZ, JOSÉ M.},
  title     = {Survey about citation context analysis: Tasks, techniques, and resources},
  journal   = {Natural Language Engineering},
  year      = {2016},
  volume    = {22},
  number    = {3},
  pages     = {327–349},
  note      = {"r"},
  doi       = {10.1017/S1351324915000388},
  publisher = {Cambridge University Press},
  review    = {- good overview (many citations) for citation context identification and citation function classification, etc.
- overview table with different schemes for classifying citation functions},
}

@Article{Moravcsik1975,
  author    = {Michael J. Moravcsik and Poovanalingam Murugesan},
  title     = {Some Results on the Function and Quality of Citations},
  journal   = {Social Studies of Science},
  year      = {1975},
  volume    = {5},
  number    = {1},
  pages     = {86--92},
  issn      = {03063127},
  publisher = {Sage Publications, Ltd.},
  review    = {- even earlier: (Garfield, 1964;  Weinstock, 1971)
- standard citation for citation function
- Teufel 2006: "A plethora of manual annotation schemes for citation motivation have been invented over the years. One of the best-known of these studies (Moravcsik and Murugesan, 1975) divides citations in running text into four dimensions: 
    - conceptual or operational use (i.e., use of theory vs. use of technical method)
    - evolutionary or juxtapositional (i.e., own work is based on the cited work vs. own work is analternative to it)
    - organic or perfunctory (i.e., work is crucially needed for understanding of citing article or just a general acknowledgement)
    - conformative vs.negational (i.e., is the correctness of the findings disputed?)
-> according to Petric2007 above categories are not all applicaple in all fields of research
    "Swales (1986), for instance, found that the first two criteria were irrelevant in the case of texts in applied linguistics."},
  url       = {http://www.jstor.org/stable/284557},
}

@InProceedings{Teufel2006a,
  author    = {Teufel, Simone and Siddharthan, Advaith and Tidhar, Dan},
  title     = {Automatic Classification of Citation Function},
  booktitle = {Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing},
  year      = {2006},
  series    = {EMNLP '06},
  pages     = {103--110},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  acmid     = {1610091},
  isbn      = {1-932432-73-6},
  location  = {Sydney, Australia},
  numpages  = {8},
  review    = {- mby useful for claim based approach},
  url       = {http://dl.acm.org/citation.cfm?id=1610075.1610091},
}

@InProceedings{Teufel2006b,
  author    = {Simone Teufel and Advaith Siddharthan and Dan Tidhar},
  title     = {An annotation scheme for citation function},
  booktitle = {In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue},
  year      = {2006},
  review    = {- mby useful for claim based approach},
}

@InProceedings{Abu-Jbara2013,
  author    = {Abu-Jbara, Amjad and Ezra, Jefferson and Radev, Dragomir},
  title     = {Purpose and Polarity of Citation: Towards NLP-based Bibliometrics},
  booktitle = {Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  year      = {2013},
  pages     = {596--606},
  publisher = {Association for Computational Linguistics},
  location  = {Atlanta, Georgia},
  review    = {- citation function classes: criticizing, comparison, use, substantiating, basis, neutral (other)},
  url       = {http://aclweb.org/anthology/N13-1067},
}

@Article{Petric2007,
  author   = {Bojana Petrić},
  title    = {Rhetorical functions of citations in high- and low-rated master's theses},
  journal  = {Journal of English for Academic Purposes},
  year     = {2007},
  volume   = {6},
  number   = {3},
  pages    = {238 - 253},
  issn     = {1475-1585},
  abstract = {This study compares rhetorical citation functions in eight high- and eight low-graded master's theses in the field of gender studies, written in English as a second language. The following rhetorical functions of citations are identified: attribution, exemplification, further reference, statement of use, application, evaluation, establishing links between sources, and comparison of one's own work with that of other authors. It is shown that both sets of theses use citations predominantly for attribution, suggesting that one of the functions of citation in student writing is knowledge display. The use of citation for non-attribution functions is found to be considerably lower in the low-rated theses than in the high-rated theses, both in the whole theses and in individual chapters. The findings show that there is a relationship between citation use and thesis grade, thus pointing to the importance of effective citation strategies for students’ academic success. In conclusion, the paper argues that source use and citation skills should receive more attention in EAP instruction and suggests activities focusing on this area of academic writing.},
  doi      = {https://doi.org/10.1016/j.jeap.2007.09.002},
  keywords = {Citation, Master's thesis, Academic writing, High- and low-rated writing, English for academic purposes},
  review   = {- types of citation typologies: content based vs. based on formal criteria
- classifies Moravcsik1975 as a "content based citation typology"
-},
  url      = {http://www.sciencedirect.com/science/article/pii/S1475158507000379},
}

@InProceedings{Lamers2018,
  author    = {Lamers, Wout and Eck , Nees Jan van and Waltman, Ludo and Hoos, Holger},
  title     = {Patterns in citation context: the case of the field of scientometrics},
  booktitle = {STI 2018 Conference proceedings},
  year      = {2018},
  pages     = {1114--1122},
  publisher = {Centre for Science and Technology Studies (CWTS)},
  url       = {http://hdl.handle.net/1887/65235},
}

@Article{RAHUL2017,
  author    = {JHA, RAHUL and JBARA, AMJAD-ABU and QAZVINIAN, VAHED and RADEV, DRAGOMIR R.},
  title     = {NLP-driven citation analysis for scientometrics},
  journal   = {Natural Language Engineering},
  year      = {2017},
  volume    = {23},
  number    = {1},
  pages     = {93–130},
  doi       = {10.1017/S1351324915000443},
  publisher = {Cambridge University Press},
}

@Article{Swales1986,
  author  = {Swales, John},
  title   = {Citation Analysis and Discourse Analysis},
  journal = {Applied Linguistics},
  year    = {1986},
  volume  = {7},
  number  = {1},
  pages   = {39-56},
  doi     = {10.1093/applin/7.1.39},
  eprint  = {/oup/backfile/content_public/journal/applij/7/1/10.1093_applin_7.1.39/1/39.pdf},
  review  = {- "frequently expressed concern about the adequacy and reliability of simple and straightforward citation counting."

    - negative/critical citations != good (-> high count of citations not necessarily good)
    - *important work can be absorbed into the background knowledge of a subject and is then no longer referenced (e.g. Einstein 1905 for the Theory  of Relativity)
    - *morphological and syntactic evolutions:
         - discoveries  become  'named'  (Lotka's  Law,  the  Mossbauer Effect)
         - Proper Name adjectivization takes place (Widdowsonian dichotomies, a Sinclo-Coulthardian approach)
    - citations vary in length
    - are self-citations of the same value as citations by others?

    *relevant in the same way as some citations become obsolete because of newer findings},
  url     = {http://dx.doi.org/10.1093/applin/7.1.39},
}

@Book{Swales1990,
  title     = {Genre analysis: English in academic and research settings},
  publisher = {Cambridge University Press},
  year      = {1990},
  author    = {Swales, John},
  review    = {- distinction between integral and non-integral citations
    "An integral citation is one in which the name of the researcher occurs in the actual citing sentence as some sentence-element;
     in a non-integral citation, the researcher occurs either in parenthesis or is referred to elsewehre by a superscript number or via some other device"
    -> examples in following text; not on Google books but in UB
    
    - in Thompson2001's words: "His primary distinction is between citation forms that are non-integral and those that are integral:
      the former are citations that are outside the sentence, usually placed within brackets, and that play no explicit grammatical role in the sentence,
      while the latter are those that play an explicit grammatical role within a sentence."

    - is, in contrast to citation function, about the "surface form" of the citation
    -> relevant to cit. rec. when thinking of end user system where suggestions come in while typing (-> doesn't really work for integral citations)
    -> relevant to cit. rec. in any other aspect? analysis/representation of cit. contexts?},
}

@PhdThesis{Thompson2001,
  author = {Thompson, Paul},
  title  = {A pedagogically-motivated corpus-based examination of PhD theses: Macrostructure, citation practices and uses of modal verbs},
  school = {University of Reading},
  year   = {2001},
  review = {- Nice overview of integral vs. non-integral citation (Swales -> Hyland -> ...)},
}

@Article{Hyland1999,
  author        = {Hyland, K},
  title         = {Academic attribution: citation and the construction of disciplinary knowledge},
  journal       = {Applied Linguistics},
  year          = {1999},
  volume        = {20},
  number        = {3},
  pages         = {341-367},
  __markedentry = {[tarek:]},
  doi           = {10.1093/applin/20.3.341},
  eprint        = {/oup/backfile/content_public/journal/applij/20/3/10.1093/applin/20.3.341/2/200341.pdf},
  review        = {- nice example sentences for integral vs. non-integral citations
    + mentions [42] style citations ("In the physical sciences, of course, journal styles often require numerical-
                                                      endnote forms, which reduces the prominence of cited authors considerably")
- per field ratio of integral vs. non-integral for corpus of 80 research articles
    - e.g.: bio 10/90, phys 17/83, philosophy 65/35},
  url           = {http://dx.doi.org/10.1093/applin/20.3.341},
}

@Comment{jabref-meta: databaseType:bibtex;}
