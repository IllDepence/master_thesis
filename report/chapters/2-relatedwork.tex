\chapter{Related Work}\label{chap:relatedwork}

To the best of our knowledge there is, so far, almost no work investigating (1) the use of explicit senamtic representations for (2) the task of local citation recommendation. We will therefore present related work in two areas. First, semantic approaches to citation/paper recommendation in general (global as well as local). Second, local citation recommendation regardless of the specifics of the approach taken.

Note that SemCir~\cite{Zarrinkalam2013} (see below) is the only case of a semantic approach to local citation recommendation we are aware of. The explicit semantic representations are, however, not generated from citation contexts (local) but from papers (global) that are textually (not necessarily semantically) similar to the citation contexts.

\section{Semantic approaches to citation recommendation}

At a point in time where publishing research papers online was an emerging trend, Middleton et al.~\cite{Middleton2001} propose a system for paper recommendation making use of a topic ontology. Based on classifying papers into topics and recording which papers a researcher would access on the web, they employ content-based filtering, collaborative filtering and a feedback mechanism to suggest papers from new topics to users. Comparing the topic ontology to a flat list of topics in two user studies, they report 7--15\% more user satisfaction for the ontology case.
% \cite{Middleton2004} reports on new/extended system using CORA as ontology base (evaluation is somewhat convoluted though)

In a similar vein, Zhang et al.~\cite{Zhang2008} propose a hybrid recommender system for papers based on semantic concept similarity. They derive concepts from CiteULike\footnote{See \url{http://citeulike.org/}.} tags and use these to measure the semantic similarity of papers and users' interest. In their evaluation they compare different settings of the approach but do not compare to other work or alternative techniques.

Jiang et al.~\cite{Jiang2012} use CiteULike tags as academic concepts to build a topic model applied to paper abstracts. In a content-based recommendation setting they let volunteers judge the relevance of recommendations for a test set of 30 papers. The evaluation includes a TFIDF baseline, latent Dirichlet allocation (LDA) and an approach combining LDA with their concept model. The reported MAP@5 and NDCG@5 values are best for the LDA+concept method.

In \cite{Zarrinkalam2012} Zarrinkalam et al. enrich their metadata on research papers using multiple Linked Open Data (LOD) sources to drive a hybrid recommender system. They compare a purely content-based method using only text similarity with a second method additionally utilizing collaborative filtering and a third method furthermore using the LOD enriched data. They report recall, co-cited probability and NDCG values for various cut-off values for which the LOD enriched method consistently achieves the best performance.

With SemCiR~\cite{Zarrinkalam2013} Zarrinkalam et al. introduce a content-based, global citation recommendation approach that utilizes a semantic distance measure between papers. They furthermore introcude a method for extending the measure to determine the semantic distance between an input text and a paper, which is achieved by representing the input by textually similar papers. The distance measure suggested builds on six different relational features including shared authors, venue, and overlapping in- and outgoing citations. The approach is evaluated on a 12,500 paper subset of CiteSeer\textsuperscript{x}~\cite{Caragea2014} in a citation re-prediction setting, using as input a paper's title, abstract and contexts in other papers where it was referred to. An evaluation of different scenarios measuring recall, co-cited probability and NDCG leads the authors to conclude that recommendation results can be improved by using their semantic distance measure and including citation contexts in the measurement textual similarity.

% non paper/cit:

% Using NEL + dependency trees for music recommendation\cite{Sordo2015}

% Leveraging Semantic Annotations to Link Wikipedia and News Archives\cite{Mishra2016}

% DiNoia\cite{DiNoia2012}

\section{Local citation recommendation}

Probably one of the first investigations into local citation recommendation is the work of He et al.~\cite{He2010}. They propose a two-step system that first identifies recommendation candidates and then re-ranks them by concept similarity. While also discussing global citation recommendation in detail, for the local case they compare recommending for a single context and recommending for all contexts within a document simultaneously. In an evaluation on the CiteSeer\textsuperscript{x} data set measured by recall, co-cited probability and NDCG they find that the single context task is harder, but also, that their approach to the all contexts task achieves results comparable to and even better than some global citation recommendation methods.

In a follow-up work Huang et al.~\cite{Huang2014} build upon above work by swapping out the computationally complex concept based re-ranking method with a translational model. In this model citation contexts are treated as the source language and cited papers as words in the target language. The resulting system, RefSeer, is evaluated on two smaller data sets (CiteULike and a CiteSeer subset) and one large one (all of CiteSeer). The authors report precision, recall, Bpref and MRR values for the two smaller data sets and conclude that their system can give correct recommendations in a realistic setting---such as when only the top 10 recommendations are shown.

Huang et al. improve RefSeer with a neural probabilistic model that learns distributed representations of words and documents in \cite{Huang2015}. They evaluate their model for local citation recommendation on the whole of CiteSeer, splitting between train and test set at the year 2011 (9M contexts train, 1.5M contexts test). Measuring MAP, MRR and NDCG they show that their model outperforms 4 different state-of-the-art approaches. An analysis on the influence of papers' citation counts on recommendation performance shows that their approach especially exceeds other work in case of lesser cited papers (<100 citations).

In \cite{Duma2014} Duma et al. test the effectiveness of using a variety of document internal and external text inputs with a TFIDF model. Their data set is built from the ACL Anthology and contains 5446 citations. In a re-prediction setting the authors measure how reliably their models rank the correct paper at the top position. % @"how reliably" construct: authors say "accuracy" but is the term used correctly?
They conclude that a mixture of internal and external inputs outperforms either of the aforementioned used on their own.

The work presented in \cite{Duma2016} by Duma et al. focusses on the rethorical function of sentences. The authors classify sentences using the Core Scientific Concepts (CoreSC) scheme and investigate how their distinction can be used to improve recommendation. Evaluating on one million papers from the PubMed Central Open Access Subset they measure NDCG values and find that for several classes of input sentences significant gains in recommendation quality can be made by focussing on certain rethoric passages of candidate documents when ranking text similarity.

The Neural Citation Network (NCN) proposed by Ebesu et al. in \cite{Ebesu2017} is inspired by neural machine translation, learns citation context representations as well as auhtor representations and includes an attention mechanism. For their evaluation the authors use 4.5 million citation contexts from the RefSeer data set and report NDCG, MAP, MRR and recall values. They compare against a BM25 baseline, a citation translation model as well as two variations of their model that do not make use of author representations. While BM25 is outperformed by all of the other approaches to some degree the NCN's results lead the evaluation by a distinct margin.

Kobayashi et al.~\cite{Kobayashi2018} describe a variation of local citation recommendation they call \emph{context-based co-citation recommendation}. The input here is a citation context \emph{plus} one publication referred to in that contexts. The goal then is to recommend other publications that also can be used as citations in that contexts. By classifying text sections into the discourse facets ``objective'', ``method'', and ``result'' the authors are able to train distributed vector representations per facet which are then used for the recommendation. They evaluate their approach on contexts from the ACL Anthology containing ``enumerated co-citations'' (e.g. \emph{[27,42]}) and report NDCG values at a cut-off of 100. In comparison with two baseline methods their discourse facets are shown to be effective.

In \cite{Jeong2019} Jeong et al. introduce an appraoch to local citation recommendation using Graph Convolutional Networks (GCN) and Bidirectional Encoder Representations from Transformers (BERT). The GCN is used to capture information from the citation relationships between papers, while the pre-trained BERT is applied on the citation contexts themselves. The authors evaluate their approach on a subset of 6500 papers from the ACL Anthology and a self-created data set of close to 5000 papers. They report MAP, MRR and recall values at different cut-offs demostrating that their BERT+CGN approach outperforms several reduced versions of the aforementioned as well as a baseline model.
