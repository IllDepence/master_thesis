\chapter{Conclusion}\label{chap:conclusion}
% overflow of new publications, not possible to keep overview
% remedies are actively researched, but:
In the comparatively young field of local citation recommendation, the explicit semantic modelling of citation contexts is not well explored yet. In order to investigate the merit of such approaches, we generated a new data set from arXiv \LaTeX{} sources with high quality citation marker positions and reference resolution. Using this data set we develop semantic models of citation contexts based on entities as well as claim stctures. We then evaluate our models on several data sets in a re-prediction setting as well as in a small user study. One of the entity based models, NPmarker, which captures noun phrases preceding the citation marker, performs best at low cut-offs and in the MRR metric. Low cut-offs and measuring the MRR can be interpreted as emulating citations for reference publications. This interpretation is also backed by the results of the user study, where NPmarker outperformed all other models when recommending for citation contexts, that referenced a NE or concept. We therefore conclude that NPmarker is well suited for recommending such types of citations. Our claim based model on its own does not compare in performance to a BoW baseline, but outperformes aforementioned when linearly combined with it(Claim+BoW). We take this as an indication that the model captures important information which the non-semantic BoW model is not able to reflect. In the user study Claim+BoW performs best for citation contexts, in which a claim is backed by the target citation. This suggests that the model indeed captures information related to claim strucutres.

Claim model relying on BoW "base" to outperform BoW at least suggests, that on it's own it is not very effective *generally* (for all citation types). Might be that also Claim model is well suited only for certain types of citations -> needs more investigation (see future work)

in *general* citation recommendation, a BoW/TFIDF baseline seems hard to beat, but developing specialized models for different types of citations seems promising (future work: first classify, then apply appropriate recommender)
